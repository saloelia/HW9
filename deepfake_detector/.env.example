# DeepFake Detector Configuration
# Copy this file to .env and fill in your values

# ===========================================
# LLM API Configuration
# ===========================================
# Choose your LLM provider: "anthropic" or "openai"
LLM_PROVIDER=anthropic

# Anthropic API Key (required if LLM_PROVIDER=anthropic)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# OpenAI API Key (required if LLM_PROVIDER=openai)
OPENAI_API_KEY=your_openai_api_key_here

# Model to use
# For Anthropic: claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307
# For OpenAI: gpt-4-turbo, gpt-4, gpt-3.5-turbo
LLM_MODEL=claude-3-sonnet-20240229

# ===========================================
# Detection Configuration
# ===========================================
# Maximum number of frames to analyze per video
MAX_FRAMES_TO_ANALYZE=30

# Frame sampling rate (analyze every Nth frame)
FRAME_SAMPLE_RATE=5

# Confidence threshold for detection (0.0 - 1.0)
DETECTION_THRESHOLD=0.7

# ===========================================
# Processing Configuration
# ===========================================
# Number of parallel workers for frame processing
NUM_WORKERS=4

# Enable GPU acceleration if available
USE_GPU=false

# ===========================================
# Output Configuration
# ===========================================
# Directory for saving results
OUTPUT_DIR=./results

# Enable detailed logging
DEBUG_MODE=false

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO
