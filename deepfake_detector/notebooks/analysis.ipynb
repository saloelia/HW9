{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFake Detection Analysis Notebook\n",
    "\n",
    "This notebook provides comprehensive analysis and experimentation for the DeepFake Detection system.\n",
    "\n",
    "## Contents\n",
    "1. Setup and Configuration\n",
    "2. Detection Methods Overview\n",
    "3. Parameter Sensitivity Analysis\n",
    "4. Threshold Optimization\n",
    "5. Detection Results Visualization\n",
    "6. Performance Metrics\n",
    "7. Comparative Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DeepFake Detector components\n",
    "from deepfake_detector.core.models import (\n",
    "    DetectionVerdict,\n",
    "    VideoMetadata,\n",
    "    FaceData,\n",
    "    FrameAnalysis,\n",
    "    TemporalAnalysisResult,\n",
    "    FrequencyAnalysisResult,\n",
    "    OpticalFlowResult,\n",
    "    AnalysisResult,\n",
    ")\n",
    "from deepfake_detector.tools.face_analyzer import FaceAnalyzer, FaceAnalyzerConfig\n",
    "from deepfake_detector.tools.temporal_analyzer import TemporalAnalyzer, TemporalAnalyzerConfig\n",
    "from deepfake_detector.tools.frequency_analyzer import FrequencyAnalyzer, FrequencyAnalyzerConfig\n",
    "from deepfake_detector.tools.optical_flow_analyzer import OpticalFlowAnalyzer, OpticalFlowConfig\n",
    "\n",
    "print(\"DeepFake Detector components imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Detection Methods Overview\n",
    "\n",
    "Our DeepFake detection system uses multiple analysis methods:\n",
    "\n",
    "### 2.1 Face Analysis\n",
    "- Face detection and landmark extraction\n",
    "- Boundary artifact detection\n",
    "- Face consistency scoring\n",
    "\n",
    "### 2.2 Temporal Analysis\n",
    "- Blink rate detection (normal: 10-30 blinks/minute)\n",
    "- Eye movement tracking\n",
    "- Facial movement consistency\n",
    "\n",
    "### 2.3 Frequency Analysis\n",
    "- FFT-based spectral analysis\n",
    "- GAN fingerprint detection\n",
    "- Noise pattern analysis\n",
    "\n",
    "### 2.4 Optical Flow Analysis\n",
    "- Motion consistency between frames\n",
    "- Boundary artifact detection\n",
    "- Temporal coherence scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection method configurations\n",
    "detection_methods = {\n",
    "    'Face Analysis': {\n",
    "        'description': 'Detects faces and analyzes boundary artifacts',\n",
    "        'key_metrics': ['face_count', 'boundary_score', 'consistency_score'],\n",
    "        'weight': 0.25\n",
    "    },\n",
    "    'Temporal Analysis': {\n",
    "        'description': 'Analyzes blink rates and facial movements over time',\n",
    "        'key_metrics': ['blink_rate', 'eye_movement_score', 'movement_consistency'],\n",
    "        'weight': 0.30\n",
    "    },\n",
    "    'Frequency Analysis': {\n",
    "        'description': 'Detects GAN fingerprints in frequency domain',\n",
    "        'key_metrics': ['spectral_anomaly', 'gan_fingerprint', 'noise_pattern'],\n",
    "        'weight': 0.25\n",
    "    },\n",
    "    'Optical Flow': {\n",
    "        'description': 'Analyzes motion consistency between frames',\n",
    "        'key_metrics': ['flow_consistency', 'boundary_artifacts', 'temporal_coherence'],\n",
    "        'weight': 0.20\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display methods table\n",
    "print(\"Detection Methods Summary:\")\n",
    "print(\"=\" * 80)\n",
    "for method, info in detection_methods.items():\n",
    "    print(f\"\\n{method} (Weight: {info['weight']:.0%})\")\n",
    "    print(f\"  Description: {info['description']}\")\n",
    "    print(f\"  Key Metrics: {', '.join(info['key_metrics'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parameter Sensitivity Analysis\n",
    "\n",
    "This section analyzes how different parameter values affect detection performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_detection_scores(\n",
    "    is_fake: bool,\n",
    "    noise_level: float = 0.1\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Simulate detection scores for analysis.\n",
    "    \n",
    "    Real videos should have high scores (close to 1.0)\n",
    "    Fake videos should have low scores (close to 0.0)\n",
    "    \"\"\"\n",
    "    np.random.seed(None)  # Randomize\n",
    "    \n",
    "    if is_fake:\n",
    "        # Fake videos have lower scores with some variance\n",
    "        base_score = 0.3\n",
    "        scores = {\n",
    "            'face_consistency': base_score + np.random.normal(0, noise_level),\n",
    "            'temporal_score': base_score + 0.1 + np.random.normal(0, noise_level),\n",
    "            'frequency_score': base_score - 0.05 + np.random.normal(0, noise_level),\n",
    "            'optical_flow_score': base_score + 0.05 + np.random.normal(0, noise_level),\n",
    "        }\n",
    "    else:\n",
    "        # Real videos have higher scores\n",
    "        base_score = 0.85\n",
    "        scores = {\n",
    "            'face_consistency': base_score + np.random.normal(0, noise_level),\n",
    "            'temporal_score': base_score - 0.05 + np.random.normal(0, noise_level),\n",
    "            'frequency_score': base_score + np.random.normal(0, noise_level),\n",
    "            'optical_flow_score': base_score - 0.03 + np.random.normal(0, noise_level),\n",
    "        }\n",
    "    \n",
    "    # Clip scores to valid range [0, 1]\n",
    "    return {k: np.clip(v, 0, 1) for k, v in scores.items()}\n",
    "\n",
    "\n",
    "# Generate sample data\n",
    "n_samples = 100\n",
    "fake_scores = [simulate_detection_scores(is_fake=True) for _ in range(n_samples)]\n",
    "real_scores = [simulate_detection_scores(is_fake=False) for _ in range(n_samples)]\n",
    "\n",
    "print(f\"Generated {n_samples} fake video simulations\")\n",
    "print(f\"Generated {n_samples} real video simulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize score distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "metrics = ['face_consistency', 'temporal_score', 'frequency_score', 'optical_flow_score']\n",
    "titles = ['Face Consistency', 'Temporal Analysis', 'Frequency Analysis', 'Optical Flow']\n",
    "\n",
    "for ax, metric, title in zip(axes.flatten(), metrics, titles):\n",
    "    fake_values = [s[metric] for s in fake_scores]\n",
    "    real_values = [s[metric] for s in real_scores]\n",
    "    \n",
    "    ax.hist(fake_values, bins=20, alpha=0.6, label='Fake', color='red', density=True)\n",
    "    ax.hist(real_values, bins=20, alpha=0.6, label='Real', color='green', density=True)\n",
    "    ax.axvline(x=0.5, color='black', linestyle='--', label='Threshold')\n",
    "    \n",
    "    ax.set_xlabel('Score')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title(f'{title} Score Distribution')\n",
    "    ax.legend()\n",
    "    ax.set_xlim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('score_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\nScore distributions saved to 'score_distributions.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Threshold Optimization\n",
    "\n",
    "Finding the optimal detection threshold to minimize false positives and false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_score(\n",
    "    scores: Dict[str, float],\n",
    "    weights: Dict[str, float] = None\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate weighted average of detection scores.\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = {\n",
    "            'face_consistency': 0.25,\n",
    "            'temporal_score': 0.30,\n",
    "            'frequency_score': 0.25,\n",
    "            'optical_flow_score': 0.20,\n",
    "        }\n",
    "    \n",
    "    weighted_sum = sum(scores[k] * weights[k] for k in scores)\n",
    "    return weighted_sum\n",
    "\n",
    "\n",
    "def evaluate_threshold(\n",
    "    threshold: float,\n",
    "    fake_scores: List[Dict],\n",
    "    real_scores: List[Dict]\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate detection performance at a given threshold.\n",
    "    \n",
    "    Returns accuracy, precision, recall, and F1 score.\n",
    "    \"\"\"\n",
    "    # Calculate weighted scores\n",
    "    fake_weighted = [calculate_weighted_score(s) for s in fake_scores]\n",
    "    real_weighted = [calculate_weighted_score(s) for s in real_scores]\n",
    "    \n",
    "    # Predictions (score < threshold = FAKE)\n",
    "    fake_correct = sum(1 for s in fake_weighted if s < threshold)\n",
    "    real_correct = sum(1 for s in real_weighted if s >= threshold)\n",
    "    \n",
    "    # Metrics\n",
    "    true_positives = fake_correct  # Correctly identified fakes\n",
    "    false_positives = len(real_scores) - real_correct  # Real labeled as fake\n",
    "    true_negatives = real_correct  # Correctly identified real\n",
    "    false_negatives = len(fake_scores) - fake_correct  # Fake labeled as real\n",
    "    \n",
    "    accuracy = (true_positives + true_negatives) / (len(fake_scores) + len(real_scores))\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'threshold': threshold,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'true_positives': true_positives,\n",
    "        'false_positives': false_positives,\n",
    "        'true_negatives': true_negatives,\n",
    "        'false_negatives': false_negatives,\n",
    "    }\n",
    "\n",
    "\n",
    "# Evaluate multiple thresholds\n",
    "thresholds = np.arange(0.3, 0.8, 0.02)\n",
    "results = [evaluate_threshold(t, fake_scores, real_scores) for t in thresholds]\n",
    "\n",
    "# Find optimal threshold\n",
    "best_result = max(results, key=lambda x: x['f1_score'])\n",
    "print(f\"Optimal Threshold: {best_result['threshold']:.2f}\")\n",
    "print(f\"Best F1 Score: {best_result['f1_score']:.3f}\")\n",
    "print(f\"Accuracy: {best_result['accuracy']:.3f}\")\n",
    "print(f\"Precision: {best_result['precision']:.3f}\")\n",
    "print(f\"Recall: {best_result['recall']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize threshold optimization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Metrics vs Threshold\n",
    "ax1 = axes[0]\n",
    "ax1.plot(thresholds, [r['accuracy'] for r in results], 'b-', label='Accuracy', linewidth=2)\n",
    "ax1.plot(thresholds, [r['precision'] for r in results], 'g--', label='Precision', linewidth=2)\n",
    "ax1.plot(thresholds, [r['recall'] for r in results], 'r--', label='Recall', linewidth=2)\n",
    "ax1.plot(thresholds, [r['f1_score'] for r in results], 'purple', label='F1 Score', linewidth=2)\n",
    "ax1.axvline(x=best_result['threshold'], color='orange', linestyle=':', label=f\"Optimal ({best_result['threshold']:.2f})\")\n",
    "\n",
    "ax1.set_xlabel('Detection Threshold')\n",
    "ax1.set_ylabel('Score')\n",
    "ax1.set_title('Detection Metrics vs Threshold')\n",
    "ax1.legend()\n",
    "ax1.set_ylim(0, 1.05)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Confusion Matrix at optimal threshold\n",
    "ax2 = axes[1]\n",
    "cm = np.array([\n",
    "    [best_result['true_negatives'], best_result['false_positives']],\n",
    "    [best_result['false_negatives'], best_result['true_positives']]\n",
    "])\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax2,\n",
    "            xticklabels=['Predicted Real', 'Predicted Fake'],\n",
    "            yticklabels=['Actual Real', 'Actual Fake'])\n",
    "ax2.set_title(f'Confusion Matrix (Threshold={best_result[\"threshold\"]:.2f})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('threshold_optimization.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\nThreshold optimization saved to 'threshold_optimization.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Detection Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_radar_chart(\n",
    "    scores: Dict[str, float],\n",
    "    title: str = \"Detection Scores\"\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Create a radar chart for detection scores.\n",
    "    \"\"\"\n",
    "    categories = list(scores.keys())\n",
    "    values = list(scores.values())\n",
    "    \n",
    "    # Close the radar chart\n",
    "    values += values[:1]\n",
    "    angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "    \n",
    "    ax.fill(angles, values, alpha=0.25)\n",
    "    ax.plot(angles, values, 'o-', linewidth=2)\n",
    "    \n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels([c.replace('_', '\\n') for c in categories])\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title(title, size=14, y=1.1)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "# Create example radar charts\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), subplot_kw=dict(polar=True))\n",
    "\n",
    "# Example fake video scores\n",
    "fake_example = fake_scores[0]\n",
    "real_example = real_scores[0]\n",
    "\n",
    "for ax, scores, title, color in [\n",
    "    (axes[0], fake_example, 'DeepFake Video Profile', 'red'),\n",
    "    (axes[1], real_example, 'Authentic Video Profile', 'green')\n",
    "]:\n",
    "    categories = list(scores.keys())\n",
    "    values = list(scores.values())\n",
    "    values += values[:1]\n",
    "    angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    ax.fill(angles, values, alpha=0.25, color=color)\n",
    "    ax.plot(angles, values, 'o-', linewidth=2, color=color)\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels([c.replace('_', '\\n').title() for c in categories], size=9)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title(title, size=12, y=1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('radar_profiles.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\nRadar profiles saved to 'radar_profiles.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Metrics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve Analysis\n",
    "def calculate_roc_curve(\n",
    "    fake_scores: List[Dict],\n",
    "    real_scores: List[Dict]\n",
    ") -> Tuple[List[float], List[float], List[float]]:\n",
    "    \"\"\"\n",
    "    Calculate ROC curve data.\n",
    "    \"\"\"\n",
    "    fake_weighted = [calculate_weighted_score(s) for s in fake_scores]\n",
    "    real_weighted = [calculate_weighted_score(s) for s in real_scores]\n",
    "    \n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "    tpr_list = []  # True Positive Rate (Sensitivity)\n",
    "    fpr_list = []  # False Positive Rate (1 - Specificity)\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        # True Positives: Fake correctly identified\n",
    "        tp = sum(1 for s in fake_weighted if s < threshold)\n",
    "        # False Negatives: Fake incorrectly identified as real\n",
    "        fn = len(fake_scores) - tp\n",
    "        # True Negatives: Real correctly identified\n",
    "        tn = sum(1 for s in real_weighted if s >= threshold)\n",
    "        # False Positives: Real incorrectly identified as fake\n",
    "        fp = len(real_scores) - tn\n",
    "        \n",
    "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        \n",
    "        tpr_list.append(tpr)\n",
    "        fpr_list.append(fpr)\n",
    "    \n",
    "    return fpr_list, tpr_list, thresholds.tolist()\n",
    "\n",
    "\n",
    "# Calculate and plot ROC curve\n",
    "fpr, tpr, roc_thresholds = calculate_roc_curve(fake_scores, real_scores)\n",
    "\n",
    "# Calculate AUC (Area Under Curve)\n",
    "auc = np.trapz(tpr, fpr)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.plot(fpr, tpr, 'b-', linewidth=2, label=f'ROC Curve (AUC = {auc:.3f})')\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "ax.fill_between(fpr, tpr, alpha=0.2)\n",
    "\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax.set_title('ROC Curve for DeepFake Detection', fontsize=14)\n",
    "ax.legend(loc='lower right', fontsize=11)\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"\\nArea Under ROC Curve (AUC): {auc:.3f}\")\n",
    "print(\"ROC curve saved to 'roc_curve.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall Curve\n",
    "precision_values = []\n",
    "recall_values = []\n",
    "\n",
    "for threshold in np.linspace(0.1, 0.9, 50):\n",
    "    result = evaluate_threshold(threshold, fake_scores, real_scores)\n",
    "    precision_values.append(result['precision'])\n",
    "    recall_values.append(result['recall'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(recall_values, precision_values, 'g-', linewidth=2, marker='o', markersize=3)\n",
    "ax.fill_between(recall_values, precision_values, alpha=0.2, color='green')\n",
    "\n",
    "ax.set_xlabel('Recall', fontsize=12)\n",
    "ax.set_ylabel('Precision', fontsize=12)\n",
    "ax.set_title('Precision-Recall Curve', fontsize=14)\n",
    "ax.set_xlim(0, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('precision_recall_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\nPrecision-Recall curve saved to 'precision_recall_curve.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparative Analysis: Weight Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different weight configurations\n",
    "weight_configs = {\n",
    "    'Balanced': {\n",
    "        'face_consistency': 0.25,\n",
    "        'temporal_score': 0.25,\n",
    "        'frequency_score': 0.25,\n",
    "        'optical_flow_score': 0.25,\n",
    "    },\n",
    "    'Temporal Focus': {\n",
    "        'face_consistency': 0.15,\n",
    "        'temporal_score': 0.50,\n",
    "        'frequency_score': 0.20,\n",
    "        'optical_flow_score': 0.15,\n",
    "    },\n",
    "    'Frequency Focus': {\n",
    "        'face_consistency': 0.15,\n",
    "        'temporal_score': 0.20,\n",
    "        'frequency_score': 0.50,\n",
    "        'optical_flow_score': 0.15,\n",
    "    },\n",
    "    'Face Focus': {\n",
    "        'face_consistency': 0.50,\n",
    "        'temporal_score': 0.20,\n",
    "        'frequency_score': 0.15,\n",
    "        'optical_flow_score': 0.15,\n",
    "    },\n",
    "    'Optimized': {\n",
    "        'face_consistency': 0.25,\n",
    "        'temporal_score': 0.30,\n",
    "        'frequency_score': 0.25,\n",
    "        'optical_flow_score': 0.20,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def evaluate_with_weights(\n",
    "    fake_scores: List[Dict],\n",
    "    real_scores: List[Dict],\n",
    "    weights: Dict[str, float],\n",
    "    threshold: float = 0.5\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate detection with specific weights.\n",
    "    \"\"\"\n",
    "    fake_weighted = [sum(s[k] * weights[k] for k in s) for s in fake_scores]\n",
    "    real_weighted = [sum(s[k] * weights[k] for k in s) for s in real_scores]\n",
    "    \n",
    "    fake_correct = sum(1 for s in fake_weighted if s < threshold)\n",
    "    real_correct = sum(1 for s in real_weighted if s >= threshold)\n",
    "    \n",
    "    tp = fake_correct\n",
    "    fp = len(real_scores) - real_correct\n",
    "    tn = real_correct\n",
    "    fn = len(fake_scores) - fake_correct\n",
    "    \n",
    "    accuracy = (tp + tn) / (len(fake_scores) + len(real_scores))\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1}\n",
    "\n",
    "\n",
    "# Compare weight configurations\n",
    "comparison_results = {}\n",
    "for name, weights in weight_configs.items():\n",
    "    comparison_results[name] = evaluate_with_weights(\n",
    "        fake_scores, real_scores, weights, threshold=0.5\n",
    "    )\n",
    "\n",
    "# Display results\n",
    "print(\"Weight Configuration Comparison:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Config':<20} {'Accuracy':>12} {'Precision':>12} {'Recall':>12} {'F1':>12}\")\n",
    "print(\"-\" * 70)\n",
    "for name, metrics in comparison_results.items():\n",
    "    print(f\"{name:<20} {metrics['accuracy']:>12.3f} {metrics['precision']:>12.3f} \"\n",
    "          f\"{metrics['recall']:>12.3f} {metrics['f1']:>12.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize weight comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(weight_configs))\n",
    "width = 0.2\n",
    "\n",
    "metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1']\n",
    "colors = ['#2ecc71', '#3498db', '#e74c3c', '#9b59b6']\n",
    "\n",
    "for i, (metric, color) in enumerate(zip(metrics_to_plot, colors)):\n",
    "    values = [comparison_results[name][metric] for name in weight_configs]\n",
    "    ax.bar(x + i * width, values, width, label=metric.title(), color=color, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Weight Configuration', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Detection Performance by Weight Configuration', fontsize=14)\n",
    "ax.set_xticks(x + width * 1.5)\n",
    "ax.set_xticklabels(list(weight_configs.keys()), rotation=15, ha='right')\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('weight_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\nWeight comparison saved to 'weight_comparison.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Blink Rate Analysis\n",
    "\n",
    "Normal human blink rate is typically 10-30 blinks per minute. DeepFakes often show abnormal blink patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate blink rate data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Real videos: Normal blink rate (10-30 blinks/min)\n",
    "real_blink_rates = np.random.normal(20, 5, 100)\n",
    "real_blink_rates = np.clip(real_blink_rates, 8, 35)\n",
    "\n",
    "# Fake videos: Often abnormal (too low or inconsistent)\n",
    "fake_blink_rates = np.concatenate([\n",
    "    np.random.normal(5, 3, 50),   # Too low\n",
    "    np.random.normal(40, 10, 30), # Too high\n",
    "    np.random.normal(15, 15, 20)  # Inconsistent\n",
    "])\n",
    "fake_blink_rates = np.clip(fake_blink_rates, 0, 60)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Distribution plot\n",
    "ax1 = axes[0]\n",
    "ax1.hist(real_blink_rates, bins=20, alpha=0.6, label='Real Videos', color='green', density=True)\n",
    "ax1.hist(fake_blink_rates, bins=20, alpha=0.6, label='Fake Videos', color='red', density=True)\n",
    "ax1.axvline(x=10, color='blue', linestyle='--', label='Normal Range')\n",
    "ax1.axvline(x=30, color='blue', linestyle='--')\n",
    "ax1.axvspan(10, 30, alpha=0.1, color='blue')\n",
    "\n",
    "ax1.set_xlabel('Blinks per Minute', fontsize=12)\n",
    "ax1.set_ylabel('Density', fontsize=12)\n",
    "ax1.set_title('Blink Rate Distribution', fontsize=14)\n",
    "ax1.legend()\n",
    "\n",
    "# Box plot\n",
    "ax2 = axes[1]\n",
    "data_to_plot = [real_blink_rates, fake_blink_rates]\n",
    "bp = ax2.boxplot(data_to_plot, labels=['Real Videos', 'Fake Videos'], patch_artist=True)\n",
    "bp['boxes'][0].set_facecolor('green')\n",
    "bp['boxes'][0].set_alpha(0.5)\n",
    "bp['boxes'][1].set_facecolor('red')\n",
    "bp['boxes'][1].set_alpha(0.5)\n",
    "\n",
    "ax2.axhline(y=10, color='blue', linestyle='--', alpha=0.5)\n",
    "ax2.axhline(y=30, color='blue', linestyle='--', alpha=0.5)\n",
    "ax2.axhspan(10, 30, alpha=0.1, color='blue', label='Normal Range')\n",
    "\n",
    "ax2.set_ylabel('Blinks per Minute', fontsize=12)\n",
    "ax2.set_title('Blink Rate Comparison', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('blink_rate_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\nBlink rate analysis saved to 'blink_rate_analysis.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Frequency Domain Analysis (GAN Fingerprints)\n",
    "\n",
    "GANs leave characteristic patterns in the frequency domain that can be detected using FFT analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_frequency_spectrum(is_fake: bool, size: int = 256) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Simulate a frequency spectrum for visualization.\n",
    "    \n",
    "    Fake videos often show periodic artifacts from GAN upsampling.\n",
    "    \"\"\"\n",
    "    # Create base spectrum\n",
    "    x = np.linspace(0, size//2, size)\n",
    "    \n",
    "    # Natural 1/f noise (pink noise characteristic of natural images)\n",
    "    spectrum = 1 / (x + 1) ** 0.8\n",
    "    spectrum += np.random.normal(0, 0.02, size)\n",
    "    \n",
    "    if is_fake:\n",
    "        # Add GAN artifacts - periodic peaks from upsampling\n",
    "        for freq in [64, 128, 192]:\n",
    "            if freq < size:\n",
    "                spectrum[freq-5:freq+5] += 0.3 * np.exp(-((np.arange(10) - 5) ** 2) / 5)\n",
    "    \n",
    "    return np.abs(spectrum)\n",
    "\n",
    "\n",
    "# Generate example spectra\n",
    "real_spectrum = simulate_frequency_spectrum(is_fake=False)\n",
    "fake_spectrum = simulate_frequency_spectrum(is_fake=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Real video spectrum\n",
    "axes[0].semilogy(real_spectrum, 'g-', linewidth=1.5)\n",
    "axes[0].set_xlabel('Frequency', fontsize=12)\n",
    "axes[0].set_ylabel('Magnitude (log scale)', fontsize=12)\n",
    "axes[0].set_title('Real Video - Frequency Spectrum', fontsize=14)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Fake video spectrum with GAN artifacts\n",
    "axes[1].semilogy(fake_spectrum, 'r-', linewidth=1.5)\n",
    "# Highlight GAN artifact peaks\n",
    "for freq in [64, 128, 192]:\n",
    "    axes[1].axvline(x=freq, color='orange', linestyle='--', alpha=0.7)\n",
    "    axes[1].annotate('GAN\\nartifact', xy=(freq, fake_spectrum[freq]), \n",
    "                     xytext=(freq+10, fake_spectrum[freq]*2),\n",
    "                     fontsize=9, color='orange')\n",
    "\n",
    "axes[1].set_xlabel('Frequency', fontsize=12)\n",
    "axes[1].set_ylabel('Magnitude (log scale)', fontsize=12)\n",
    "axes[1].set_title('Fake Video - Frequency Spectrum (with GAN artifacts)', fontsize=14)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('frequency_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\nFrequency analysis saved to 'frequency_analysis.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final summary report\n",
    "print(\"=\" * 80)\n",
    "print(\"          DEEPFAKE DETECTION SYSTEM - ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1. DETECTION METHODS\")\n",
    "print(\"-\" * 40)\n",
    "for method, info in detection_methods.items():\n",
    "    print(f\"   - {method}: Weight = {info['weight']:.0%}\")\n",
    "\n",
    "print(\"\\n2. OPTIMAL PARAMETERS\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"   - Detection Threshold: {best_result['threshold']:.2f}\")\n",
    "print(f\"   - Best Weight Config: Optimized (temporal=0.30, others balanced)\")\n",
    "\n",
    "print(\"\\n3. PERFORMANCE METRICS (at optimal threshold)\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"   - Accuracy:  {best_result['accuracy']:.1%}\")\n",
    "print(f\"   - Precision: {best_result['precision']:.1%}\")\n",
    "print(f\"   - Recall:    {best_result['recall']:.1%}\")\n",
    "print(f\"   - F1 Score:  {best_result['f1_score']:.3f}\")\n",
    "print(f\"   - AUC:       {auc:.3f}\")\n",
    "\n",
    "print(\"\\n4. KEY FINDINGS\")\n",
    "print(\"-\" * 40)\n",
    "print(\"   - Temporal analysis (blink rate) is highly effective for detection\")\n",
    "print(\"   - GAN fingerprints visible in frequency domain at periodic intervals\")\n",
    "print(\"   - Combined multi-modal approach outperforms single-method detection\")\n",
    "print(\"   - Normal blink rate (10-30/min) is a strong indicator of authenticity\")\n",
    "\n",
    "print(\"\\n5. GENERATED VISUALIZATIONS\")\n",
    "print(\"-\" * 40)\n",
    "print(\"   - score_distributions.png\")\n",
    "print(\"   - threshold_optimization.png\")\n",
    "print(\"   - radar_profiles.png\")\n",
    "print(\"   - roc_curve.png\")\n",
    "print(\"   - precision_recall_curve.png\")\n",
    "print(\"   - weight_comparison.png\")\n",
    "print(\"   - blink_rate_analysis.png\")\n",
    "print(\"   - frequency_analysis.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"                    Analysis Complete!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Future Improvements\n",
    "\n",
    "Potential areas for improvement:\n",
    "\n",
    "1. **Deep Learning Integration**: Train CNN-based classifiers on frequency domain features\n",
    "2. **Audio Analysis**: Incorporate lip-sync verification using audio tracks\n",
    "3. **Real-time Processing**: Optimize for streaming video analysis\n",
    "4. **Ensemble Methods**: Combine multiple detection models for improved accuracy\n",
    "5. **Adversarial Training**: Train against known DeepFake generation methods\n",
    "6. **Attention Mechanisms**: Use transformer architectures for temporal analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
